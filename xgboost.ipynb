{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "seed_set = 311  # Just my BD\n",
    "np.random.seed(seed_set)\n",
    "\n",
    "# Plotting libs\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [16, 10]\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AVG_EARTH_RADIUS = 6371  # in km\n",
    "\n",
    "\n",
    "def haversine(point1, point2, miles=False):\n",
    "    \"\"\" Calculate the great-circle distance between two points on the Earth surface.\n",
    "    :input: two 2-tuples, containing the latitude and longitude of each point\n",
    "    in decimal degrees.\n",
    "    Example: haversine((45.7597, 4.8422), (48.8567, 2.3508))\n",
    "    :output: Returns the distance bewteen the two points.\n",
    "    The default unit is kilometers. Miles can be returned\n",
    "    if the ``miles`` parameter is set to True.\n",
    "    \"\"\"\n",
    "\n",
    "    # Unpack latitude/longitude\n",
    "    lat1, lng1 = point1\n",
    "    lat2, lng2 = point2\n",
    "\n",
    "    # Convert all latitudes/longitudes from decimal degrees to radians\n",
    "    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n",
    "\n",
    "    # Calculate haversine\n",
    "    lat, lng= lat2 - lat1, lng2 - lng1\n",
    "    d = np.sin(lat * 0.5) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(lng * 0.5) ** 2\n",
    "    h = 2 * AVG_EARTH_RADIUS * np.arcsin(np.sqrt(d))\n",
    "    return h * 0.621371 if miles else h # in m/km\n",
    "\n",
    "\n",
    "def dummy_manhattan_distance(point1, point2):\n",
    "    lat1, lng1 = point1\n",
    "    lat2, lng2 = point2\n",
    "    a = haversine((lat1, lng1), (lat1, lng2))\n",
    "    b = haversine((lat1, lng1), (lat2, lng1))\n",
    "\n",
    "    return haversine((lat1, lng1), (lat1, lng2)) + haversine((lat1, lng1), (lat2, lng1))\n",
    "\n",
    "\n",
    "def bearing_array(lat1, lng1, lat2, lng2):\n",
    "    AVG_EARTH_RADIUS = 6371  # in km\n",
    "    lng_delta_rad = np.radians(lng2 - lng1)\n",
    "    (lat1, lng1, lat2, lng2) = map(np.radians, (lat1, lng1, lat2, lng2))\n",
    "    y = np.sin(lng_delta_rad) * np.cos(lat2)\n",
    "    x = np.cos(lat1) * np.sin(lat2) - np.sin(lat1) * np.cos(lat2) * np.cos(lng_delta_rad)\n",
    "    \n",
    "    return np.degrees(np.arctan2(y, x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Features\n",
    "\n",
    "- id - a unique identifier for each trip\n",
    "- vendor_id - a code indicating the provider associated with the trip record\n",
    "- pickup_datetime - date and time when the meter was engaged\n",
    "- dropoff_datetime - date and time when the meter was disengaged\n",
    "- passenger_count - the number of passengers in the vehicle (driver entered value)\n",
    "- pickup_longitude - the longitude where the meter was engaged\n",
    "- pickup_latitude - the latitude where the meter was engaged\n",
    "- dropoff_longitude - the longitude where the meter was disengaged\n",
    "- dropoff_latitude - the latitude where the meter was disengaged\n",
    "- store_and_fwd_flag - This flag indicates whether the trip record was held in vehicle memory before sending to the vendor because the vehicle did not have a connection to the server - Y=store and forward; N=not a store and forward trip\n",
    "- trip_duration - duration of the trip in seconds\n",
    "\n",
    "## Build Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build features based on longitutde/latitude\n",
    "train['distance_haversine'] = haversine(\n",
    "    (train['pickup_latitude'].values, train['pickup_longitude'].values),\n",
    "    (train['dropoff_latitude'].values, train['dropoff_longitude'].values)\n",
    ")\n",
    "train['distance_dummy_manhattan'] = dummy_manhattan_distance(\n",
    "    (train['pickup_latitude'].values, train['pickup_longitude'].values),\n",
    "    (train['dropoff_latitude'].values, train['dropoff_longitude'].values)\n",
    ")\n",
    "train['direction'] = bearing_array(train['pickup_latitude'].values, train['pickup_longitude'].values, train['dropoff_latitude'].values, train['dropoff_longitude'].values)\n",
    "train['center_latitude'] = (train['pickup_latitude'].values + train['dropoff_latitude'].values) / 2\n",
    "train['center_longitude'] = (train['pickup_longitude'].values + train['dropoff_longitude'].values) / 2\n",
    "\n",
    "test['distance_haversine'] = haversine(\n",
    "    (test['pickup_latitude'].values, test['pickup_longitude'].values),\n",
    "    (test['dropoff_latitude'].values, test['dropoff_longitude'].values)\n",
    ")\n",
    "\n",
    "test['distance_dummy_manhattan'] = dummy_manhattan_distance(\n",
    "    (test['pickup_latitude'].values, test['pickup_longitude'].values),\n",
    "    (test['dropoff_latitude'].values, test['dropoff_longitude'].values)\n",
    ")\n",
    "test['direction'] = bearing_array(test['pickup_latitude'].values, test['pickup_longitude'].values, test['dropoff_latitude'].values, test['dropoff_longitude'].values)\n",
    "test['center_latitude'] = (test['pickup_latitude'].values + test['dropoff_latitude'].values) / 2\n",
    "test['center_longitude'] = (test['pickup_longitude'].values + test['dropoff_longitude'].values) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['pickup_datetime'] = pd.to_datetime(train['pickup_datetime'])\n",
    "test['pickup_datetime'] = pd.to_datetime(train['pickup_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['pickup_date'] = train['pickup_datetime'].dt.date\n",
    "train['pickup_weekday'] = train['pickup_datetime'].dt.weekday\n",
    "train['pickup_day'] = train['pickup_datetime'].dt.day\n",
    "train['pickup_month'] = train['pickup_datetime'].dt.month\n",
    "train['pickup_hour'] = train['pickup_datetime'].dt.hour\n",
    "train['pickup_minute'] = train['pickup_datetime'].dt.minute\n",
    "train['pickup_am'] = train['pickup_hour'] < 12\n",
    "\n",
    "test['pickup_date'] = test['pickup_datetime'].dt.date\n",
    "test['pickup_weekday'] = test['pickup_datetime'].dt.weekday\n",
    "test['pickup_day'] = test['pickup_datetime'].dt.day\n",
    "test['pickup_month'] = test['pickup_datetime'].dt.month\n",
    "test['pickup_hour'] = test['pickup_datetime'].dt.hour\n",
    "test['pickup_minute'] = test['pickup_datetime'].dt.minute\n",
    "test['pickup_am'] = test['pickup_hour'] < 12\n",
    "\n",
    "# These time periods are based on visuls below\n",
    "train['night_trip'] = [True if x < 7 else False for x in train['pickup_hour']]\n",
    "train['rush_hour'] = [True if 9 < x < 20 else False for x in train['pickup_hour']]\n",
    "train['weekday'] = [True if x < 5 else False for x in train['pickup_weekday']]\n",
    "test['night_trip'] = [True if x < 7 else False for x in test['pickup_hour']]\n",
    "test['rush_hour'] = [True if 9 < x < 20 else False for x in test['pickup_hour']]\n",
    "test['weekday'] = [True if x < 5 else False for x in test['pickup_weekday']]\n",
    "\n",
    "log_trip_duration = np.log(train['trip_duration'].values + 1)\n",
    "train['log_trip_duration'] = log_trip_duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train['log_trip_duration'].values, bins=100)\n",
    "plt.xlabel('log(trip_duration)')\n",
    "plt.ylabel('number of train records')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train.groupby('pickup_date').count()[['id']], 'o-', label='train')\n",
    "plt.plot(test.groupby('pickup_date').count()[['id']], 'o-', label='test')\n",
    "plt.title('Train and test period complete overlap.')\n",
    "plt.legend(loc=0)\n",
    "plt.ylabel('number of records')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100000\n",
    "fig, ax = plt.subplots(ncols=2, sharex=True, sharey=True)\n",
    "ax[0].plot(train['pickup_longitude'].values[:N], train['pickup_latitude'].values[:N], 'b.',\n",
    "           label='train', alpha=0.1)\n",
    "ax[1].plot(test['pickup_longitude'].values[:N], test['pickup_latitude'].values[:N], 'g.',\n",
    "           label='test', alpha=0.1)\n",
    "fig.suptitle('Train and test area complete overlap.')\n",
    "ax[0].legend(loc=0)\n",
    "ax[0].set_ylabel('latitude')\n",
    "ax[0].set_xlabel('longitude')\n",
    "ax[1].set_xlabel('longitude')\n",
    "ax[1].legend(loc=0)\n",
    "plt.ylim([40.5, 41])\n",
    "plt.xlim([-74.5, -73.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = pd.concat([train, test])\n",
    "coords = np.vstack((full[['pickup_latitude', 'pickup_longitude']], \n",
    "                   full[['dropoff_latitude', 'dropoff_longitude']]))\n",
    "coords.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA().fit(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['pickup_pca0'] = pca.transform(train[['pickup_latitude', 'pickup_longitude']])[:, 0]\n",
    "train['pickup_pca1'] = pca.transform(train[['pickup_latitude', 'pickup_longitude']])[:, 1]\n",
    "train['dropoff_pca0'] = pca.transform(train[['dropoff_latitude', 'dropoff_longitude']])[:, 0]\n",
    "train['dropoff_pca1'] = pca.transform(train[['dropoff_latitude', 'dropoff_longitude']])[:, 1]\n",
    "train['pca_manhattan'] = np.abs(train['dropoff_pca1'] - train['pickup_pca1']) + np.abs(train['dropoff_pca0'] - train['pickup_pca0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['pickup_pca0'] = pca.transform(test[['pickup_latitude', 'pickup_longitude']])[:, 0]\n",
    "test['pickup_pca1'] = pca.transform(test[['pickup_latitude', 'pickup_longitude']])[:, 1]\n",
    "test['dropoff_pca0'] = pca.transform(test[['dropoff_latitude', 'dropoff_longitude']])[:, 0]\n",
    "test['dropoff_pca1'] = pca.transform(test[['dropoff_latitude', 'dropoff_longitude']])[:, 1]\n",
    "test['pca_manhattan'] = np.abs(test['dropoff_pca1'] - test['pickup_pca1']) + np.abs(test['dropoff_pca0'] - test['pickup_pca0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DO_NOT_USE_FOR_TRAINING = [\n",
    "    'id', 'pickup_datetime', 'dropoff_datetime', 'pickup_longitude', 'pickup_latitude',\n",
    "    'dropoff_longitude','dropoff_latitude', 'trip_duration', 'pickup_date', 'log_trip_duration'\n",
    "]\n",
    "\n",
    "new_df = train.drop([col for col in DO_NOT_USE_FOR_TRAINING if col in train], axis=1)\n",
    "new_df_test = test.drop([col for col in DO_NOT_USE_FOR_TRAINING if col in test], axis=1)\n",
    "\n",
    "new_df['store_and_fwd_flag'] = 1 *  new_df['store_and_fwd_flag'] == True\n",
    "new_df_test['store_and_fwd_flag'] = 1 *  new_df['store_and_fwd_flag'] == True\n",
    "new_df.shape, new_df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.columns == new_df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use log to handle outliers\n",
    "y = np.log(train['trip_duration'].values)\n",
    "train_attr = np.array(new_df)\n",
    "train_attr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, val_x, train_y, val_y = train_test_split(train_attr, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save some memory, if you have >=6G, just comment this out\n",
    "del train, train_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(train_x, label=train_y)\n",
    "dvalid = xgb.DMatrix(val_x, label=val_y)\n",
    "dtest = xgb.DMatrix(new_df_test.values)\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'valid')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune these params, see https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
    "xgb_pars = {'min_child_weight': 100, 'eta': 0.1, 'colsample_bytree': 0.7, 'max_depth': 15,\n",
    "            'subsample': 0.8, 'lambda': 1., 'nthread': -1, 'booster' : 'gbtree', 'silent': 1,\n",
    "            'eval_metric': 'rmse', 'objective': 'reg:linear'}\n",
    "\n",
    "model_xgb = xgb.train(xgb_pars, dtrain, 500, watchlist, early_stopping_rounds=50,\n",
    "                  maximize=False, verbose_eval=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('XGB Modeling RMSLE %.5f' % model_xgb.best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(y_pred - y_true), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TREE_REGRESSORS = [\n",
    "    # These model are not tunned, default params in using\n",
    "    DecisionTreeRegressor(),\n",
    "    RandomForestRegressor()\n",
    "]\n",
    "\n",
    "models = []\n",
    "for regressor in TREE_REGRESSORS:\n",
    "    clf = regressor\n",
    "    clf = clf.fit(train_x, train_y)\n",
    "    models.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    # train_y is logged so rmse computes rmsle\n",
    "    train_rmsle = rmse(train_y, model.predict(train_x))\n",
    "    val_rmsle = rmse(val_y, model.predict(val_x))\n",
    "    print('With model: {}\\nTrain RMSLE: {}\\nVal. RMSLE: {}'.format(model, train_rmsle, val_rmsle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_attr = np.array(new_df_test)\n",
    "model_rt, model_rf = models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rt = model_rt.predict(test_attr)\n",
    "pred_rt = np.exp(pred_rt)\n",
    "pred_rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([test['id'], pd.DataFrame(pred_rt, columns=['trip_duration'])], axis=1)\n",
    "submission.to_csv('submission-rt.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rf = model_rf.predict(test_attr)\n",
    "pred_rf = np.exp(pred_rf)\n",
    "pred_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([test['id'], pd.DataFrame(pred_rf, columns=['trip_duration'])], axis=1)\n",
    "submission.to_csv('submission-rf.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_xgb = model_xgb.predict(dtest)\n",
    "pred_xgb = np.exp(pred_xgb)\n",
    "print('Test shape OK.') if test.shape[0] == pred_xgb.shape[0] else print('Oops')\n",
    "pred_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = pd.concat([test['id'], pd.DataFrame(pred_xgb, columns=['trip_duration'])], axis=1)\n",
    "submission.to_csv('submission-xgb.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
